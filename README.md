# üéôÔ∏è Assistente de Voz Local: Evolu√ß√£o do Desafio DIO
Este projeto √© uma evolu√ß√£o do desafio pr√°tico da DIO (Digital Innovation One). 
O objetivo original era integrar o Whisper e a API do ChatGPT para criar um assistente de voz multi-idiomas.

## üöÄ O Desafio:
Durante o desenvolvimento, o desafio proposto utilizava a API da OpenAI. Devido a limita√ß√µes financeiras para o uso de cr√©ditos e instabilidades em APIs externas, a arquitetura foi completamente adaptada.
A solu√ß√£o final utiliza IA de borda (Edge AI), rodando modelos de linguagem de grande porte (LLMs) localmente no Google Colab. Isso torna o projeto 100% gratuito e funcional, sem depender de chaves externas ou saldo.

## üõ†Ô∏è Tecnologias e Bibliotecas Utilizadas
Para que o sistema funcione de forma independente da nuvem, integramos bibliotecas de ponta no ecossistema Python:

* **OpenAI Whisper:**
* O que faz: √â o motor de reconhecimento de fala (Speech-to-Text).
Fun√ß√£o no projeto: Ele "ouve" o seu √°udio e o transforma em texto com alta precis√£o.

* **Transformers (Hugging Face):**
O que faz: A biblioteca principal para carregar modelos de IA de √∫ltima gera√ß√£o.
Fun√ß√£o no projeto: Usada para rodar o modelo Qwen2.5-1.5B-Instruct, que atua como o "c√©rebro" do assistente, processando perguntas e gerando respostas.

* **Accelerate & Bitsandbytes:**
O que faz: Ferramentas de otimiza√ß√£o de hardware.
Fun√ß√£o no projeto: Permitem que modelos pesados de IA caibam na mem√≥ria do Google Colab atrav√©s de quantiza√ß√£o, rodando velozmente na GPU T4.

* **gTTS (Google Text-to-Speech):**
O que faz: Sintetizador de voz.
Fun√ß√£o no projeto: Transforma a resposta de texto gerada pela IA de volta em √°udio.

* **IPython.display (Audio/Javascript):**
O que faz: Interfaces para o ambiente Jupyter.
Fun√ß√£o no projeto: Usado para criar a interface de grava√ß√£o no navegador e o player de resposta.

## üß† Fluxo de Execu√ß√£o

1. Input: O usu√°rio grava uma pergunta por voz via interface JavaScript no Colab.
2. STT (Whisper): O √°udio √© transcrito localmente para texto.
3. Processamento (LLM Local): O texto √© enviado ao modelo Qwen2.5 (em substitui√ß√£o ao ChatGPT), que gera uma resposta inteligente.
4. Output (gTTS): O texto da resposta √© convertido em voz e reproduzido automaticamente.

## üåü Diferenciais deste Reposit√≥rio

Independ√™ncia de API: Funciona sem necessidade de cart√µes de cr√©dito ou faturas da OpenAI.
Resili√™ncia T√©cnica: Supera erros de rede e restri√ß√µes de modelos fechados.
Privacidade: O processamento da transcri√ß√£o e do racioc√≠nio √© feito localmente no ambiente de execu√ß√£o.

## üìã Como Rodar
1. Abra o notebook no Google Colab.
2. Certifique-se de que o Acelerador de Hardware est√° definido como GPU T4.
3. Execute todas as c√©lulas em ordem.

üîó **Link do Projeto no Colab**: [Acesse aqui](https://colab.research.google.com/drive/1o8hbWMhN7AXtUmhMvpIqcRCPSk-3hQl1#scrollTo=6OZTsI_oyj3z)
